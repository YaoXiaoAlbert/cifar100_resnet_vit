{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23653770-f830-4568-8836-2ddb53d0d8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from timm.models.vision_transformer import vit_small_patch16_224\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "621e0a8b-d3a5-48b1-b682-e274588d9f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# CutMix数据增强\n",
    "def cutmix_data(x, y, alpha=1.0):\n",
    "    indices = torch.randperm(x.size(0))\n",
    "    shuffled_x = x[indices]\n",
    "    shuffled_y = y[indices]\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
    "    x[:, :, bbx1:bbx2, bby1:bby2] = shuffled_x[:, :, bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "    return x, y, shuffled_y, lam\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "# Mixup数据增强\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    \n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "# 数据预处理\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value='random'),\n",
    "    transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762)),\n",
    "])\n",
    "\n",
    "# 加载数据集\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80b89f5e-1848-4059-bdea-2120076a10d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义预训练的ViT Small模型\n",
    "class ViTCIFAR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ViTCIFAR, self).__init__()\n",
    "        self.model = vit_small_patch16_224(pretrained=False)\n",
    "        self.model.head = nn.Linear(self.model.head.in_features, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "net = ViTCIFAR()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae41c55c-4a35-469c-8a06-73ae002d8130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(net.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "# 初始化TensorBoard\n",
    "writer = SummaryWriter('vit/experiment_vit')\n",
    "\n",
    "# 记录最高准确率\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbee099f-c87b-4e6a-8680-ac76a8f554d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training Loss: 4.524, Training Accuracy: 2.42%, Validation Loss: 4.201, Validation Accuracy: 5.99%\n",
      "Epoch 2: Training Loss: 4.438, Training Accuracy: 3.37%, Validation Loss: 4.164, Validation Accuracy: 6.24%\n",
      "Epoch 3: Training Loss: 4.397, Training Accuracy: 4.01%, Validation Loss: 4.135, Validation Accuracy: 7.36%\n",
      "Epoch 4: Training Loss: 4.367, Training Accuracy: 4.24%, Validation Loss: 3.985, Validation Accuracy: 9.47%\n",
      "Epoch 5: Training Loss: 4.361, Training Accuracy: 4.40%, Validation Loss: 4.039, Validation Accuracy: 8.34%\n",
      "Epoch 6: Training Loss: 4.340, Training Accuracy: 4.73%, Validation Loss: 3.932, Validation Accuracy: 10.24%\n",
      "Epoch 8: Training Loss: 4.306, Training Accuracy: 5.34%, Validation Loss: 3.899, Validation Accuracy: 10.34%\n",
      "Epoch 9: Training Loss: 4.299, Training Accuracy: 5.33%, Validation Loss: 3.871, Validation Accuracy: 11.47%\n",
      "Epoch 10: Training Loss: 4.289, Training Accuracy: 5.66%, Validation Loss: 3.861, Validation Accuracy: 12.25%\n",
      "Epoch 11: Training Loss: 4.262, Training Accuracy: 6.09%, Validation Loss: 3.797, Validation Accuracy: 12.39%\n",
      "Epoch 12: Training Loss: 4.251, Training Accuracy: 6.09%, Validation Loss: 3.766, Validation Accuracy: 12.14%\n",
      "Epoch 13: Training Loss: 4.231, Training Accuracy: 6.60%, Validation Loss: 3.746, Validation Accuracy: 13.31%\n",
      "Epoch 14: Training Loss: 4.227, Training Accuracy: 6.59%, Validation Loss: 3.726, Validation Accuracy: 14.16%\n",
      "Epoch 15: Training Loss: 4.218, Training Accuracy: 6.73%, Validation Loss: 3.683, Validation Accuracy: 14.62%\n",
      "Epoch 16: Training Loss: 4.209, Training Accuracy: 6.98%, Validation Loss: 3.654, Validation Accuracy: 15.38%\n",
      "Epoch 17: Training Loss: 4.201, Training Accuracy: 7.09%, Validation Loss: 3.644, Validation Accuracy: 15.76%\n",
      "Epoch 18: Training Loss: 4.177, Training Accuracy: 7.45%, Validation Loss: 3.638, Validation Accuracy: 15.14%\n",
      "Epoch 19: Training Loss: 4.163, Training Accuracy: 7.81%, Validation Loss: 3.609, Validation Accuracy: 15.12%\n",
      "Epoch 20: Training Loss: 4.179, Training Accuracy: 7.44%, Validation Loss: 3.563, Validation Accuracy: 16.74%\n",
      "Epoch 21: Training Loss: 4.131, Training Accuracy: 8.24%, Validation Loss: 3.528, Validation Accuracy: 17.19%\n",
      "Epoch 22: Training Loss: 4.118, Training Accuracy: 8.69%, Validation Loss: 3.489, Validation Accuracy: 19.05%\n",
      "Epoch 23: Training Loss: 4.098, Training Accuracy: 8.89%, Validation Loss: 3.425, Validation Accuracy: 19.52%\n",
      "Epoch 24: Training Loss: 4.085, Training Accuracy: 9.17%, Validation Loss: 3.414, Validation Accuracy: 19.92%\n",
      "Epoch 25: Training Loss: 4.097, Training Accuracy: 9.06%, Validation Loss: 3.420, Validation Accuracy: 19.94%\n",
      "Epoch 26: Training Loss: 4.074, Training Accuracy: 9.39%, Validation Loss: 3.368, Validation Accuracy: 21.06%\n",
      "Epoch 27: Training Loss: 4.039, Training Accuracy: 10.04%, Validation Loss: 3.297, Validation Accuracy: 22.32%\n",
      "Epoch 28: Training Loss: 4.043, Training Accuracy: 10.22%, Validation Loss: 3.256, Validation Accuracy: 23.13%\n",
      "Epoch 29: Training Loss: 4.020, Training Accuracy: 10.40%, Validation Loss: 3.276, Validation Accuracy: 22.90%\n",
      "Epoch 30: Training Loss: 4.033, Training Accuracy: 10.26%, Validation Loss: 3.232, Validation Accuracy: 23.45%\n",
      "Epoch 31: Training Loss: 3.957, Training Accuracy: 11.77%, Validation Loss: 3.118, Validation Accuracy: 25.84%\n",
      "Epoch 32: Training Loss: 3.906, Training Accuracy: 12.56%, Validation Loss: 3.067, Validation Accuracy: 26.79%\n",
      "Epoch 33: Training Loss: 3.932, Training Accuracy: 12.38%, Validation Loss: 3.057, Validation Accuracy: 26.98%\n",
      "Epoch 34: Training Loss: 3.936, Training Accuracy: 12.25%, Validation Loss: 3.054, Validation Accuracy: 26.78%\n",
      "Epoch 35: Training Loss: 3.934, Training Accuracy: 12.29%, Validation Loss: 3.052, Validation Accuracy: 27.26%\n",
      "Epoch 36: Training Loss: 3.888, Training Accuracy: 12.88%, Validation Loss: 3.019, Validation Accuracy: 27.61%\n",
      "Epoch 37: Training Loss: 3.911, Training Accuracy: 12.46%, Validation Loss: 3.001, Validation Accuracy: 27.62%\n",
      "Epoch 38: Training Loss: 3.893, Training Accuracy: 12.96%, Validation Loss: 3.015, Validation Accuracy: 27.86%\n",
      "Epoch 39: Training Loss: 3.876, Training Accuracy: 13.34%, Validation Loss: 2.982, Validation Accuracy: 28.45%\n",
      "Epoch 40: Training Loss: 3.884, Training Accuracy: 13.17%, Validation Loss: 2.985, Validation Accuracy: 28.22%\n",
      "Epoch 41: Training Loss: 3.860, Training Accuracy: 13.73%, Validation Loss: 2.972, Validation Accuracy: 28.55%\n",
      "Epoch 42: Training Loss: 3.864, Training Accuracy: 13.56%, Validation Loss: 2.953, Validation Accuracy: 29.09%\n",
      "Epoch 43: Training Loss: 3.871, Training Accuracy: 13.45%, Validation Loss: 2.960, Validation Accuracy: 28.65%\n",
      "Epoch 44: Training Loss: 3.900, Training Accuracy: 13.00%, Validation Loss: 2.963, Validation Accuracy: 28.96%\n",
      "Epoch 45: Training Loss: 3.829, Training Accuracy: 14.15%, Validation Loss: 2.928, Validation Accuracy: 29.39%\n",
      "Epoch 46: Training Loss: 3.849, Training Accuracy: 13.65%, Validation Loss: 2.949, Validation Accuracy: 29.46%\n",
      "Epoch 47: Training Loss: 3.861, Training Accuracy: 13.60%, Validation Loss: 2.952, Validation Accuracy: 29.25%\n",
      "Epoch 48: Training Loss: 3.834, Training Accuracy: 14.14%, Validation Loss: 2.919, Validation Accuracy: 29.65%\n",
      "Epoch 49: Training Loss: 3.879, Training Accuracy: 13.34%, Validation Loss: 2.929, Validation Accuracy: 29.40%\n",
      "Epoch 50: Training Loss: 3.858, Training Accuracy: 13.89%, Validation Loss: 2.921, Validation Accuracy: 29.70%\n",
      "Epoch 51: Training Loss: 3.833, Training Accuracy: 13.99%, Validation Loss: 2.904, Validation Accuracy: 29.98%\n",
      "Epoch 52: Training Loss: 3.858, Training Accuracy: 13.52%, Validation Loss: 2.906, Validation Accuracy: 30.18%\n",
      "Epoch 53: Training Loss: 3.842, Training Accuracy: 14.19%, Validation Loss: 2.904, Validation Accuracy: 29.87%\n",
      "Epoch 54: Training Loss: 3.864, Training Accuracy: 13.73%, Validation Loss: 2.908, Validation Accuracy: 30.07%\n",
      "Epoch 55: Training Loss: 3.827, Training Accuracy: 14.24%, Validation Loss: 2.892, Validation Accuracy: 30.44%\n",
      "Epoch 56: Training Loss: 3.805, Training Accuracy: 14.67%, Validation Loss: 2.909, Validation Accuracy: 30.10%\n",
      "Epoch 57: Training Loss: 3.785, Training Accuracy: 15.25%, Validation Loss: 2.876, Validation Accuracy: 30.37%\n",
      "Epoch 58: Training Loss: 3.850, Training Accuracy: 13.96%, Validation Loss: 2.885, Validation Accuracy: 30.69%\n",
      "Epoch 59: Training Loss: 3.792, Training Accuracy: 15.07%, Validation Loss: 2.874, Validation Accuracy: 30.66%\n",
      "Epoch 60: Training Loss: 3.859, Training Accuracy: 13.92%, Validation Loss: 2.879, Validation Accuracy: 30.48%\n",
      "Epoch 61: Training Loss: 3.791, Training Accuracy: 15.10%, Validation Loss: 2.860, Validation Accuracy: 30.90%\n",
      "Epoch 62: Training Loss: 3.783, Training Accuracy: 15.20%, Validation Loss: 2.849, Validation Accuracy: 31.03%\n",
      "Epoch 63: Training Loss: 3.805, Training Accuracy: 14.73%, Validation Loss: 2.851, Validation Accuracy: 30.92%\n",
      "Epoch 64: Training Loss: 3.795, Training Accuracy: 14.85%, Validation Loss: 2.846, Validation Accuracy: 31.10%\n",
      "Epoch 65: Training Loss: 3.801, Training Accuracy: 14.64%, Validation Loss: 2.851, Validation Accuracy: 31.00%\n",
      "Epoch 66: Training Loss: 3.791, Training Accuracy: 14.79%, Validation Loss: 2.848, Validation Accuracy: 31.14%\n",
      "Epoch 67: Training Loss: 3.820, Training Accuracy: 14.52%, Validation Loss: 2.849, Validation Accuracy: 31.09%\n",
      "Epoch 68: Training Loss: 3.803, Training Accuracy: 14.84%, Validation Loss: 2.849, Validation Accuracy: 31.19%\n",
      "Epoch 69: Training Loss: 3.807, Training Accuracy: 14.99%, Validation Loss: 2.845, Validation Accuracy: 31.40%\n",
      "Epoch 70: Training Loss: 3.828, Training Accuracy: 14.28%, Validation Loss: 2.850, Validation Accuracy: 31.20%\n",
      "Epoch 71: Training Loss: 3.801, Training Accuracy: 14.94%, Validation Loss: 2.844, Validation Accuracy: 31.28%\n",
      "Epoch 72: Training Loss: 3.845, Training Accuracy: 14.01%, Validation Loss: 2.851, Validation Accuracy: 31.12%\n",
      "Epoch 73: Training Loss: 3.807, Training Accuracy: 14.68%, Validation Loss: 2.845, Validation Accuracy: 31.27%\n",
      "Epoch 74: Training Loss: 3.790, Training Accuracy: 15.00%, Validation Loss: 2.842, Validation Accuracy: 31.30%\n",
      "Epoch 75: Training Loss: 3.822, Training Accuracy: 14.53%, Validation Loss: 2.844, Validation Accuracy: 31.35%\n",
      "Epoch 76: Training Loss: 3.800, Training Accuracy: 15.02%, Validation Loss: 2.842, Validation Accuracy: 31.48%\n",
      "Epoch 77: Training Loss: 3.783, Training Accuracy: 14.88%, Validation Loss: 2.838, Validation Accuracy: 31.44%\n",
      "Epoch 78: Training Loss: 3.813, Training Accuracy: 14.74%, Validation Loss: 2.840, Validation Accuracy: 31.28%\n",
      "Epoch 79: Training Loss: 3.816, Training Accuracy: 14.69%, Validation Loss: 2.843, Validation Accuracy: 31.06%\n",
      "Epoch 80: Training Loss: 3.802, Training Accuracy: 14.82%, Validation Loss: 2.844, Validation Accuracy: 31.28%\n",
      "Epoch 81: Training Loss: 3.806, Training Accuracy: 14.79%, Validation Loss: 2.842, Validation Accuracy: 31.26%\n",
      "Epoch 82: Training Loss: 3.814, Training Accuracy: 14.67%, Validation Loss: 2.841, Validation Accuracy: 31.30%\n",
      "Epoch 83: Training Loss: 3.779, Training Accuracy: 15.20%, Validation Loss: 2.837, Validation Accuracy: 31.41%\n",
      "Epoch 84: Training Loss: 3.784, Training Accuracy: 15.35%, Validation Loss: 2.833, Validation Accuracy: 31.41%\n",
      "Epoch 85: Training Loss: 3.816, Training Accuracy: 14.66%, Validation Loss: 2.839, Validation Accuracy: 31.45%\n",
      "Epoch 86: Training Loss: 3.811, Training Accuracy: 14.65%, Validation Loss: 2.836, Validation Accuracy: 31.49%\n",
      "Epoch 87: Training Loss: 3.836, Training Accuracy: 14.36%, Validation Loss: 2.842, Validation Accuracy: 31.49%\n",
      "Epoch 88: Training Loss: 3.798, Training Accuracy: 15.04%, Validation Loss: 2.836, Validation Accuracy: 31.54%\n",
      "Epoch 89: Training Loss: 3.790, Training Accuracy: 15.10%, Validation Loss: 2.831, Validation Accuracy: 31.47%\n",
      "Epoch 90: Training Loss: 3.816, Training Accuracy: 14.47%, Validation Loss: 2.835, Validation Accuracy: 31.47%\n",
      "Epoch 91: Training Loss: 3.801, Training Accuracy: 15.05%, Validation Loss: 2.835, Validation Accuracy: 31.49%\n",
      "Epoch 92: Training Loss: 3.765, Training Accuracy: 15.46%, Validation Loss: 2.833, Validation Accuracy: 31.51%\n",
      "Epoch 93: Training Loss: 3.777, Training Accuracy: 15.21%, Validation Loss: 2.833, Validation Accuracy: 31.50%\n",
      "Epoch 94: Training Loss: 3.794, Training Accuracy: 14.89%, Validation Loss: 2.832, Validation Accuracy: 31.51%\n",
      "Epoch 95: Training Loss: 3.783, Training Accuracy: 15.23%, Validation Loss: 2.832, Validation Accuracy: 31.49%\n",
      "Epoch 96: Training Loss: 3.835, Training Accuracy: 14.12%, Validation Loss: 2.833, Validation Accuracy: 31.48%\n",
      "Epoch 97: Training Loss: 3.788, Training Accuracy: 14.92%, Validation Loss: 2.832, Validation Accuracy: 31.52%\n",
      "Epoch 98: Training Loss: 3.797, Training Accuracy: 14.91%, Validation Loss: 2.832, Validation Accuracy: 31.53%\n",
      "Epoch 99: Training Loss: 3.818, Training Accuracy: 14.53%, Validation Loss: 2.832, Validation Accuracy: 31.55%\n",
      "Epoch 100: Training Loss: 3.797, Training Accuracy: 15.03%, Validation Loss: 2.832, Validation Accuracy: 31.53%\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "for epoch in range(100):  # 共训练100个epoch\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # 随机选择使用CutMix或Mixup\n",
    "        if np.random.rand() < 0.5:\n",
    "            inputs, targets_a, targets_b, lam = cutmix_data(inputs, labels)\n",
    "        else:\n",
    "            inputs, targets_a, targets_b, lam = mixup_data(inputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (lam * (predicted == targets_a).sum().item() + (1 - lam) * (predicted == targets_b).sum().item())\n",
    "\n",
    "    train_loss = running_loss / len(trainloader)\n",
    "    train_accuracy = 100 * correct / total\n",
    "\n",
    "    writer.add_scalar('training loss', train_loss, epoch)\n",
    "    writer.add_scalar('training accuracy', train_accuracy, epoch)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # 验证模型\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(testloader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "\n",
    "    writer.add_scalar('validation loss', val_loss, epoch)\n",
    "    writer.add_scalar('validation accuracy', val_accuracy, epoch)\n",
    "\n",
    "    print(f'Epoch {epoch + 1}: Training Loss: {train_loss:.3f}, Training Accuracy: {train_accuracy:.2f}%, Validation Loss: {val_loss:.3f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "    # 保存验证集上最高准确率的模型\n",
    "    if val_accuracy > best_acc:\n",
    "        best_acc = val_accuracy\n",
    "        torch.save(net.state_dict(), 'vit.pth')\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107ee601-fa57-4340-8ba6-1536ebc0659b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
