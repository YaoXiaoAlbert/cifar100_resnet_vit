{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3644742-964c-4f83-b550-6997f02867d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from timm.models.vision_transformer import vit_small_patch16_224\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a387d9de-23c4-43b3-8f5c-460f1796a592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# CutMix数据增强\n",
    "def cutmix_data(x, y, alpha=1.0):\n",
    "    indices = torch.randperm(x.size(0))\n",
    "    shuffled_x = x[indices]\n",
    "    shuffled_y = y[indices]\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
    "    x[:, :, bbx1:bbx2, bby1:bby2] = shuffled_x[:, :, bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "    return x, y, shuffled_y, lam\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "# Mixup数据增强\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    \n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "# 数据预处理\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value='random'),\n",
    "    transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762)),\n",
    "])\n",
    "\n",
    "# 加载数据集\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f70e0ed9-1de9-4d52-8d69-83d472f9809c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义预训练的ViT Small模型\n",
    "class ViTCIFAR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ViTCIFAR, self).__init__()\n",
    "        self.model = vit_small_patch16_224(pretrained=True)\n",
    "        self.model.head = nn.Linear(self.model.head.in_features, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "net = ViTCIFAR()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "443ed2af-c94b-40bf-a6c4-2b1478ba2693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(net.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "# 初始化TensorBoard\n",
    "writer = SummaryWriter('vit/experiment_vit_pretrained')\n",
    "\n",
    "# 记录最高准确率\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cb7c146-bb4f-40d7-8486-2225e0cd4efb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training Loss: 4.403, Training Accuracy: 3.93%, Validation Loss: 3.751, Validation Accuracy: 12.13%\n",
      "Epoch 2: Training Loss: 4.108, Training Accuracy: 8.51%, Validation Loss: 3.162, Validation Accuracy: 22.25%\n",
      "Epoch 3: Training Loss: 3.872, Training Accuracy: 13.10%, Validation Loss: 2.913, Validation Accuracy: 28.86%\n",
      "Epoch 5: Training Loss: 3.613, Training Accuracy: 18.56%, Validation Loss: 2.405, Validation Accuracy: 40.91%\n",
      "Epoch 6: Training Loss: 3.492, Training Accuracy: 21.04%, Validation Loss: 2.254, Validation Accuracy: 43.75%\n",
      "Epoch 7: Training Loss: 3.402, Training Accuracy: 22.91%, Validation Loss: 2.121, Validation Accuracy: 45.93%\n",
      "Epoch 8: Training Loss: 3.328, Training Accuracy: 24.90%, Validation Loss: 2.014, Validation Accuracy: 49.37%\n",
      "Epoch 9: Training Loss: 3.247, Training Accuracy: 26.40%, Validation Loss: 2.022, Validation Accuracy: 50.00%\n",
      "Epoch 10: Training Loss: 3.175, Training Accuracy: 28.24%, Validation Loss: 1.868, Validation Accuracy: 53.30%\n",
      "Epoch 11: Training Loss: 3.114, Training Accuracy: 29.48%, Validation Loss: 1.694, Validation Accuracy: 56.39%\n",
      "Epoch 12: Training Loss: 3.087, Training Accuracy: 30.09%, Validation Loss: 1.653, Validation Accuracy: 57.36%\n",
      "Epoch 13: Training Loss: 3.035, Training Accuracy: 31.48%, Validation Loss: 1.642, Validation Accuracy: 58.00%\n",
      "Epoch 14: Training Loss: 2.924, Training Accuracy: 34.05%, Validation Loss: 1.514, Validation Accuracy: 60.30%\n",
      "Epoch 15: Training Loss: 2.955, Training Accuracy: 33.51%, Validation Loss: 1.514, Validation Accuracy: 60.72%\n",
      "Epoch 16: Training Loss: 2.915, Training Accuracy: 34.27%, Validation Loss: 1.445, Validation Accuracy: 61.92%\n",
      "Epoch 17: Training Loss: 2.869, Training Accuracy: 35.68%, Validation Loss: 1.478, Validation Accuracy: 61.69%\n",
      "Epoch 18: Training Loss: 2.853, Training Accuracy: 35.81%, Validation Loss: 1.416, Validation Accuracy: 63.32%\n",
      "Epoch 19: Training Loss: 2.739, Training Accuracy: 38.25%, Validation Loss: 1.345, Validation Accuracy: 64.40%\n",
      "Epoch 20: Training Loss: 2.781, Training Accuracy: 37.47%, Validation Loss: 1.387, Validation Accuracy: 64.78%\n",
      "Epoch 21: Training Loss: 2.693, Training Accuracy: 39.51%, Validation Loss: 1.302, Validation Accuracy: 65.87%\n",
      "Epoch 22: Training Loss: 2.719, Training Accuracy: 38.95%, Validation Loss: 1.286, Validation Accuracy: 66.39%\n",
      "Epoch 23: Training Loss: 2.699, Training Accuracy: 39.26%, Validation Loss: 1.357, Validation Accuracy: 65.43%\n",
      "Epoch 24: Training Loss: 2.678, Training Accuracy: 40.05%, Validation Loss: 1.266, Validation Accuracy: 66.98%\n",
      "Epoch 25: Training Loss: 2.664, Training Accuracy: 40.22%, Validation Loss: 1.241, Validation Accuracy: 67.28%\n",
      "Epoch 26: Training Loss: 2.582, Training Accuracy: 42.05%, Validation Loss: 1.246, Validation Accuracy: 68.34%\n",
      "Epoch 27: Training Loss: 2.618, Training Accuracy: 41.34%, Validation Loss: 1.165, Validation Accuracy: 68.97%\n",
      "Epoch 28: Training Loss: 2.523, Training Accuracy: 43.50%, Validation Loss: 1.182, Validation Accuracy: 69.57%\n",
      "Epoch 29: Training Loss: 2.517, Training Accuracy: 43.85%, Validation Loss: 1.181, Validation Accuracy: 69.47%\n",
      "Epoch 30: Training Loss: 2.554, Training Accuracy: 42.59%, Validation Loss: 1.171, Validation Accuracy: 69.03%\n",
      "Epoch 31: Training Loss: 2.357, Training Accuracy: 47.71%, Validation Loss: 1.009, Validation Accuracy: 73.41%\n",
      "Epoch 32: Training Loss: 2.319, Training Accuracy: 48.38%, Validation Loss: 1.008, Validation Accuracy: 73.66%\n",
      "Epoch 33: Training Loss: 2.227, Training Accuracy: 50.39%, Validation Loss: 0.976, Validation Accuracy: 73.94%\n",
      "Epoch 34: Training Loss: 2.269, Training Accuracy: 49.61%, Validation Loss: 0.965, Validation Accuracy: 74.08%\n",
      "Epoch 35: Training Loss: 2.208, Training Accuracy: 51.14%, Validation Loss: 0.968, Validation Accuracy: 74.64%\n",
      "Epoch 36: Training Loss: 2.253, Training Accuracy: 49.84%, Validation Loss: 0.975, Validation Accuracy: 74.65%\n",
      "Epoch 37: Training Loss: 2.181, Training Accuracy: 51.51%, Validation Loss: 0.956, Validation Accuracy: 74.79%\n",
      "Epoch 38: Training Loss: 2.211, Training Accuracy: 50.76%, Validation Loss: 0.953, Validation Accuracy: 75.08%\n",
      "Epoch 39: Training Loss: 2.251, Training Accuracy: 49.77%, Validation Loss: 0.964, Validation Accuracy: 75.25%\n",
      "Epoch 40: Training Loss: 2.141, Training Accuracy: 52.72%, Validation Loss: 0.946, Validation Accuracy: 75.00%\n",
      "Epoch 41: Training Loss: 2.127, Training Accuracy: 52.84%, Validation Loss: 0.923, Validation Accuracy: 75.43%\n",
      "Epoch 42: Training Loss: 2.223, Training Accuracy: 50.54%, Validation Loss: 0.968, Validation Accuracy: 75.56%\n",
      "Epoch 43: Training Loss: 2.127, Training Accuracy: 52.31%, Validation Loss: 0.931, Validation Accuracy: 75.19%\n",
      "Epoch 44: Training Loss: 2.166, Training Accuracy: 51.80%, Validation Loss: 0.948, Validation Accuracy: 75.38%\n",
      "Epoch 45: Training Loss: 2.138, Training Accuracy: 52.30%, Validation Loss: 0.920, Validation Accuracy: 76.15%\n",
      "Epoch 46: Training Loss: 2.159, Training Accuracy: 51.85%, Validation Loss: 0.938, Validation Accuracy: 75.24%\n",
      "Epoch 47: Training Loss: 2.138, Training Accuracy: 52.07%, Validation Loss: 0.915, Validation Accuracy: 75.55%\n",
      "Epoch 48: Training Loss: 2.143, Training Accuracy: 52.27%, Validation Loss: 0.933, Validation Accuracy: 75.91%\n",
      "Epoch 49: Training Loss: 2.122, Training Accuracy: 52.89%, Validation Loss: 0.909, Validation Accuracy: 75.98%\n",
      "Epoch 50: Training Loss: 2.066, Training Accuracy: 54.17%, Validation Loss: 0.921, Validation Accuracy: 76.28%\n",
      "Epoch 51: Training Loss: 2.065, Training Accuracy: 54.21%, Validation Loss: 0.927, Validation Accuracy: 76.10%\n",
      "Epoch 52: Training Loss: 2.052, Training Accuracy: 54.62%, Validation Loss: 0.918, Validation Accuracy: 76.09%\n",
      "Epoch 53: Training Loss: 2.095, Training Accuracy: 53.23%, Validation Loss: 0.926, Validation Accuracy: 75.90%\n",
      "Epoch 54: Training Loss: 2.030, Training Accuracy: 55.01%, Validation Loss: 0.900, Validation Accuracy: 76.62%\n",
      "Epoch 55: Training Loss: 2.044, Training Accuracy: 54.38%, Validation Loss: 0.912, Validation Accuracy: 76.15%\n",
      "Epoch 56: Training Loss: 2.080, Training Accuracy: 53.80%, Validation Loss: 0.923, Validation Accuracy: 76.54%\n",
      "Epoch 57: Training Loss: 2.045, Training Accuracy: 55.16%, Validation Loss: 0.916, Validation Accuracy: 76.38%\n",
      "Epoch 58: Training Loss: 2.097, Training Accuracy: 53.73%, Validation Loss: 0.923, Validation Accuracy: 76.41%\n",
      "Epoch 59: Training Loss: 2.017, Training Accuracy: 55.27%, Validation Loss: 0.909, Validation Accuracy: 76.50%\n",
      "Epoch 60: Training Loss: 2.032, Training Accuracy: 54.78%, Validation Loss: 0.932, Validation Accuracy: 76.08%\n",
      "Epoch 61: Training Loss: 2.034, Training Accuracy: 54.87%, Validation Loss: 0.904, Validation Accuracy: 76.57%\n",
      "Epoch 62: Training Loss: 2.001, Training Accuracy: 55.72%, Validation Loss: 0.900, Validation Accuracy: 76.61%\n",
      "Epoch 63: Training Loss: 2.014, Training Accuracy: 55.41%, Validation Loss: 0.899, Validation Accuracy: 76.78%\n",
      "Epoch 65: Training Loss: 2.078, Training Accuracy: 53.54%, Validation Loss: 0.902, Validation Accuracy: 76.75%\n",
      "Epoch 66: Training Loss: 2.023, Training Accuracy: 54.88%, Validation Loss: 0.897, Validation Accuracy: 76.87%\n",
      "Epoch 67: Training Loss: 2.036, Training Accuracy: 54.64%, Validation Loss: 0.899, Validation Accuracy: 76.81%\n",
      "Epoch 68: Training Loss: 1.956, Training Accuracy: 56.79%, Validation Loss: 0.896, Validation Accuracy: 76.90%\n",
      "Epoch 69: Training Loss: 2.010, Training Accuracy: 55.00%, Validation Loss: 0.895, Validation Accuracy: 76.95%\n",
      "Epoch 70: Training Loss: 1.968, Training Accuracy: 56.10%, Validation Loss: 0.897, Validation Accuracy: 76.77%\n",
      "Epoch 71: Training Loss: 1.982, Training Accuracy: 55.94%, Validation Loss: 0.896, Validation Accuracy: 77.00%\n",
      "Epoch 72: Training Loss: 1.967, Training Accuracy: 56.32%, Validation Loss: 0.895, Validation Accuracy: 76.92%\n",
      "Epoch 73: Training Loss: 1.994, Training Accuracy: 55.83%, Validation Loss: 0.899, Validation Accuracy: 76.89%\n",
      "Epoch 74: Training Loss: 1.998, Training Accuracy: 55.45%, Validation Loss: 0.894, Validation Accuracy: 76.99%\n",
      "Epoch 75: Training Loss: 2.024, Training Accuracy: 54.92%, Validation Loss: 0.899, Validation Accuracy: 76.88%\n",
      "Epoch 76: Training Loss: 1.998, Training Accuracy: 55.33%, Validation Loss: 0.893, Validation Accuracy: 76.95%\n",
      "Epoch 77: Training Loss: 2.028, Training Accuracy: 54.49%, Validation Loss: 0.894, Validation Accuracy: 76.92%\n",
      "Epoch 78: Training Loss: 1.976, Training Accuracy: 55.84%, Validation Loss: 0.893, Validation Accuracy: 76.86%\n",
      "Epoch 79: Training Loss: 1.975, Training Accuracy: 56.06%, Validation Loss: 0.890, Validation Accuracy: 77.03%\n",
      "Epoch 80: Training Loss: 1.984, Training Accuracy: 56.28%, Validation Loss: 0.893, Validation Accuracy: 77.03%\n",
      "Epoch 81: Training Loss: 1.974, Training Accuracy: 56.36%, Validation Loss: 0.896, Validation Accuracy: 77.08%\n",
      "Epoch 82: Training Loss: 1.959, Training Accuracy: 56.55%, Validation Loss: 0.891, Validation Accuracy: 76.98%\n",
      "Epoch 83: Training Loss: 2.039, Training Accuracy: 53.93%, Validation Loss: 0.893, Validation Accuracy: 77.06%\n",
      "Epoch 84: Training Loss: 2.099, Training Accuracy: 52.88%, Validation Loss: 0.898, Validation Accuracy: 76.89%\n",
      "Epoch 85: Training Loss: 1.998, Training Accuracy: 55.34%, Validation Loss: 0.892, Validation Accuracy: 76.99%\n",
      "Epoch 86: Training Loss: 2.000, Training Accuracy: 55.25%, Validation Loss: 0.894, Validation Accuracy: 76.98%\n",
      "Epoch 87: Training Loss: 1.955, Training Accuracy: 56.61%, Validation Loss: 0.887, Validation Accuracy: 77.12%\n",
      "Epoch 88: Training Loss: 1.939, Training Accuracy: 57.53%, Validation Loss: 0.890, Validation Accuracy: 77.18%\n",
      "Epoch 89: Training Loss: 2.025, Training Accuracy: 54.73%, Validation Loss: 0.896, Validation Accuracy: 77.08%\n",
      "Epoch 90: Training Loss: 1.998, Training Accuracy: 55.47%, Validation Loss: 0.898, Validation Accuracy: 76.95%\n",
      "Epoch 91: Training Loss: 1.963, Training Accuracy: 56.65%, Validation Loss: 0.897, Validation Accuracy: 76.89%\n",
      "Epoch 92: Training Loss: 2.033, Training Accuracy: 55.11%, Validation Loss: 0.897, Validation Accuracy: 76.99%\n",
      "Epoch 93: Training Loss: 1.975, Training Accuracy: 55.95%, Validation Loss: 0.896, Validation Accuracy: 76.98%\n",
      "Epoch 94: Training Loss: 1.937, Training Accuracy: 57.47%, Validation Loss: 0.895, Validation Accuracy: 76.99%\n",
      "Epoch 95: Training Loss: 1.978, Training Accuracy: 55.78%, Validation Loss: 0.894, Validation Accuracy: 77.01%\n",
      "Epoch 96: Training Loss: 1.961, Training Accuracy: 56.50%, Validation Loss: 0.893, Validation Accuracy: 77.02%\n",
      "Epoch 97: Training Loss: 2.011, Training Accuracy: 55.41%, Validation Loss: 0.894, Validation Accuracy: 77.00%\n",
      "Epoch 98: Training Loss: 2.010, Training Accuracy: 55.14%, Validation Loss: 0.893, Validation Accuracy: 77.01%\n",
      "Epoch 99: Training Loss: 2.015, Training Accuracy: 55.22%, Validation Loss: 0.894, Validation Accuracy: 77.07%\n",
      "Epoch 100: Training Loss: 1.989, Training Accuracy: 55.88%, Validation Loss: 0.894, Validation Accuracy: 77.09%\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "for epoch in range(100):  # 共训练100个epoch\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # 随机选择使用CutMix或Mixup\n",
    "        if np.random.rand() < 0.5:\n",
    "            inputs, targets_a, targets_b, lam = cutmix_data(inputs, labels)\n",
    "        else:\n",
    "            inputs, targets_a, targets_b, lam = mixup_data(inputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (lam * (predicted == targets_a).sum().item() + (1 - lam) * (predicted == targets_b).sum().item())\n",
    "\n",
    "    train_loss = running_loss / len(trainloader)\n",
    "    train_accuracy = 100 * correct / total\n",
    "\n",
    "    writer.add_scalar('training loss', train_loss, epoch)\n",
    "    writer.add_scalar('training accuracy', train_accuracy, epoch)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # 验证模型\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(testloader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "\n",
    "    writer.add_scalar('validation loss', val_loss, epoch)\n",
    "    writer.add_scalar('validation accuracy', val_accuracy, epoch)\n",
    "\n",
    "    print(f'Epoch {epoch + 1}: Training Loss: {train_loss:.3f}, Training Accuracy: {train_accuracy:.2f}%, Validation Loss: {val_loss:.3f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "    # 保存验证集上最高准确率的模型\n",
    "    if val_accuracy > best_acc:\n",
    "        best_acc = val_accuracy\n",
    "        torch.save(net.state_dict(), 'vit_pretrained.pth')\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0a643a-aabd-4146-b42e-f5dba8d44678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
