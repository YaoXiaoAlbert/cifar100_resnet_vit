{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44afface-327f-480c-8477-03754a32bf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.models import resnet34\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbfbc8bd-4861-4448-9c89-4e7421d1bdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# CutMix数据增强\n",
    "def cutmix_data(x, y, alpha=1.0):\n",
    "    indices = torch.randperm(x.size(0))\n",
    "    shuffled_x = x[indices]\n",
    "    shuffled_y = y[indices]\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
    "    x[:, :, bbx1:bbx2, bby1:bbx2] = shuffled_x[:, :, bbx1:bbx2, bby1:bbx2]\n",
    "\n",
    "    return x, y, shuffled_y, lam\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "# 数据预处理\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762)),\n",
    "])\n",
    "\n",
    "# 加载数据集\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b6a86d0-ef53-4179-8bd9-9ab791c3e67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义ResNet-34模型\n",
    "class ResNetCIFAR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetCIFAR, self).__init__()\n",
    "        self.model = resnet34(weights=torchvision.models.ResNet34_Weights.DEFAULT)\n",
    "        self.model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.model.maxpool = nn.Identity()\n",
    "        self.model.fc = nn.Linear(512, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d15cf07-0219-45ec-b857-fea8883c48b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
      "100%|██████████| 83.3M/83.3M [05:33<00:00, 262kB/s]\n"
     ]
    }
   ],
   "source": [
    "net = ResNetCIFAR()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net = net.to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(net.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "# 初始化TensorBoard\n",
    "writer = SummaryWriter('resnet/experiment_resnet34_pretrained')\n",
    "\n",
    "# 记录最高准确率\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a6d7a1c-0adc-4a88-abb7-1804a411ba4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training Loss: 4.097, Training Accuracy: 9.41%, Validation Loss: 3.045, Validation Accuracy: 25.94%\n",
      "Epoch 2: Training Loss: 3.641, Training Accuracy: 18.32%, Validation Loss: 2.602, Validation Accuracy: 33.63%\n",
      "Epoch 3: Training Loss: 3.399, Training Accuracy: 24.20%, Validation Loss: 2.173, Validation Accuracy: 45.69%\n",
      "Epoch 4: Training Loss: 3.247, Training Accuracy: 27.31%, Validation Loss: 2.021, Validation Accuracy: 48.59%\n",
      "Epoch 5: Training Loss: 3.127, Training Accuracy: 29.97%, Validation Loss: 1.847, Validation Accuracy: 52.66%\n",
      "Epoch 6: Training Loss: 3.025, Training Accuracy: 32.30%, Validation Loss: 1.734, Validation Accuracy: 55.66%\n",
      "Epoch 7: Training Loss: 2.971, Training Accuracy: 33.41%, Validation Loss: 1.502, Validation Accuracy: 60.11%\n",
      "Epoch 8: Training Loss: 2.833, Training Accuracy: 36.36%, Validation Loss: 1.538, Validation Accuracy: 59.94%\n",
      "Epoch 9: Training Loss: 2.852, Training Accuracy: 36.05%, Validation Loss: 1.577, Validation Accuracy: 61.56%\n",
      "Epoch 10: Training Loss: 2.782, Training Accuracy: 37.57%, Validation Loss: 1.381, Validation Accuracy: 63.16%\n",
      "Epoch 11: Training Loss: 2.735, Training Accuracy: 38.90%, Validation Loss: 1.403, Validation Accuracy: 65.15%\n",
      "Epoch 12: Training Loss: 2.646, Training Accuracy: 40.49%, Validation Loss: 1.495, Validation Accuracy: 64.31%\n",
      "Epoch 13: Training Loss: 2.574, Training Accuracy: 41.27%, Validation Loss: 1.274, Validation Accuracy: 66.24%\n",
      "Epoch 14: Training Loss: 2.594, Training Accuracy: 40.85%, Validation Loss: 1.283, Validation Accuracy: 67.61%\n",
      "Epoch 15: Training Loss: 2.572, Training Accuracy: 42.31%, Validation Loss: 1.212, Validation Accuracy: 69.61%\n",
      "Epoch 16: Training Loss: 2.547, Training Accuracy: 41.73%, Validation Loss: 1.171, Validation Accuracy: 69.34%\n",
      "Epoch 17: Training Loss: 2.404, Training Accuracy: 45.21%, Validation Loss: 1.344, Validation Accuracy: 68.02%\n",
      "Epoch 18: Training Loss: 2.449, Training Accuracy: 43.71%, Validation Loss: 1.219, Validation Accuracy: 70.52%\n",
      "Epoch 19: Training Loss: 2.439, Training Accuracy: 44.45%, Validation Loss: 1.244, Validation Accuracy: 69.31%\n",
      "Epoch 20: Training Loss: 2.442, Training Accuracy: 43.77%, Validation Loss: 1.153, Validation Accuracy: 71.12%\n",
      "Epoch 21: Training Loss: 2.308, Training Accuracy: 46.28%, Validation Loss: 1.078, Validation Accuracy: 71.90%\n",
      "Epoch 22: Training Loss: 2.372, Training Accuracy: 46.21%, Validation Loss: 1.086, Validation Accuracy: 72.04%\n",
      "Epoch 23: Training Loss: 2.284, Training Accuracy: 46.53%, Validation Loss: 1.122, Validation Accuracy: 71.80%\n",
      "Epoch 24: Training Loss: 2.263, Training Accuracy: 47.40%, Validation Loss: 1.118, Validation Accuracy: 71.53%\n",
      "Epoch 25: Training Loss: 2.283, Training Accuracy: 47.80%, Validation Loss: 1.086, Validation Accuracy: 71.98%\n",
      "Epoch 26: Training Loss: 2.373, Training Accuracy: 45.48%, Validation Loss: 1.161, Validation Accuracy: 71.58%\n",
      "Epoch 27: Training Loss: 2.228, Training Accuracy: 49.42%, Validation Loss: 1.117, Validation Accuracy: 73.02%\n",
      "Epoch 28: Training Loss: 2.223, Training Accuracy: 48.05%, Validation Loss: 1.567, Validation Accuracy: 64.31%\n",
      "Epoch 29: Training Loss: 2.153, Training Accuracy: 49.82%, Validation Loss: 1.026, Validation Accuracy: 73.95%\n",
      "Epoch 30: Training Loss: 2.141, Training Accuracy: 50.09%, Validation Loss: 1.146, Validation Accuracy: 72.71%\n",
      "Epoch 31: Training Loss: 1.979, Training Accuracy: 53.80%, Validation Loss: 0.899, Validation Accuracy: 77.12%\n",
      "Epoch 32: Training Loss: 1.999, Training Accuracy: 52.74%, Validation Loss: 0.932, Validation Accuracy: 77.48%\n",
      "Epoch 33: Training Loss: 1.959, Training Accuracy: 53.61%, Validation Loss: 0.886, Validation Accuracy: 77.57%\n",
      "Epoch 34: Training Loss: 1.915, Training Accuracy: 55.95%, Validation Loss: 0.931, Validation Accuracy: 77.69%\n",
      "Epoch 37: Training Loss: 1.909, Training Accuracy: 54.42%, Validation Loss: 0.889, Validation Accuracy: 78.05%\n",
      "Epoch 38: Training Loss: 1.859, Training Accuracy: 56.86%, Validation Loss: 0.867, Validation Accuracy: 78.03%\n",
      "Epoch 39: Training Loss: 1.923, Training Accuracy: 54.72%, Validation Loss: 0.901, Validation Accuracy: 78.08%\n",
      "Epoch 40: Training Loss: 1.916, Training Accuracy: 53.80%, Validation Loss: 0.919, Validation Accuracy: 77.77%\n",
      "Epoch 41: Training Loss: 1.862, Training Accuracy: 57.48%, Validation Loss: 0.896, Validation Accuracy: 78.35%\n",
      "Epoch 42: Training Loss: 1.872, Training Accuracy: 55.70%, Validation Loss: 0.913, Validation Accuracy: 78.12%\n",
      "Epoch 43: Training Loss: 1.888, Training Accuracy: 54.55%, Validation Loss: 0.863, Validation Accuracy: 78.42%\n",
      "Epoch 44: Training Loss: 1.896, Training Accuracy: 54.43%, Validation Loss: 0.869, Validation Accuracy: 78.31%\n",
      "Epoch 45: Training Loss: 1.829, Training Accuracy: 56.73%, Validation Loss: 0.856, Validation Accuracy: 78.50%\n",
      "Epoch 46: Training Loss: 1.854, Training Accuracy: 56.06%, Validation Loss: 0.829, Validation Accuracy: 78.60%\n",
      "Epoch 47: Training Loss: 1.848, Training Accuracy: 55.95%, Validation Loss: 0.896, Validation Accuracy: 78.07%\n",
      "Epoch 48: Training Loss: 1.832, Training Accuracy: 56.66%, Validation Loss: 0.883, Validation Accuracy: 78.27%\n",
      "Epoch 49: Training Loss: 1.815, Training Accuracy: 56.64%, Validation Loss: 0.898, Validation Accuracy: 78.43%\n",
      "Epoch 50: Training Loss: 1.827, Training Accuracy: 57.05%, Validation Loss: 0.846, Validation Accuracy: 78.73%\n",
      "Epoch 51: Training Loss: 1.868, Training Accuracy: 55.20%, Validation Loss: 0.839, Validation Accuracy: 78.84%\n",
      "Epoch 52: Training Loss: 1.840, Training Accuracy: 57.11%, Validation Loss: 0.875, Validation Accuracy: 78.94%\n",
      "Epoch 53: Training Loss: 1.771, Training Accuracy: 57.67%, Validation Loss: 0.838, Validation Accuracy: 78.60%\n",
      "Epoch 54: Training Loss: 1.802, Training Accuracy: 57.05%, Validation Loss: 0.880, Validation Accuracy: 78.59%\n",
      "Epoch 55: Training Loss: 1.751, Training Accuracy: 58.50%, Validation Loss: 0.851, Validation Accuracy: 78.62%\n",
      "Epoch 56: Training Loss: 1.831, Training Accuracy: 56.48%, Validation Loss: 0.842, Validation Accuracy: 78.48%\n",
      "Epoch 57: Training Loss: 1.825, Training Accuracy: 56.31%, Validation Loss: 0.887, Validation Accuracy: 78.67%\n",
      "Epoch 58: Training Loss: 1.846, Training Accuracy: 56.84%, Validation Loss: 0.860, Validation Accuracy: 78.89%\n",
      "Epoch 59: Training Loss: 1.775, Training Accuracy: 57.60%, Validation Loss: 0.840, Validation Accuracy: 78.74%\n",
      "Epoch 60: Training Loss: 1.896, Training Accuracy: 54.92%, Validation Loss: 0.858, Validation Accuracy: 78.79%\n",
      "Epoch 61: Training Loss: 1.786, Training Accuracy: 56.74%, Validation Loss: 0.864, Validation Accuracy: 78.85%\n",
      "Epoch 62: Training Loss: 1.757, Training Accuracy: 58.18%, Validation Loss: 0.825, Validation Accuracy: 79.14%\n",
      "Epoch 63: Training Loss: 1.860, Training Accuracy: 56.49%, Validation Loss: 0.874, Validation Accuracy: 78.95%\n",
      "Epoch 64: Training Loss: 1.828, Training Accuracy: 56.97%, Validation Loss: 0.873, Validation Accuracy: 78.96%\n",
      "Epoch 65: Training Loss: 1.813, Training Accuracy: 56.81%, Validation Loss: 0.836, Validation Accuracy: 78.99%\n",
      "Epoch 66: Training Loss: 1.803, Training Accuracy: 56.78%, Validation Loss: 0.840, Validation Accuracy: 79.05%\n",
      "Epoch 67: Training Loss: 1.750, Training Accuracy: 57.31%, Validation Loss: 0.838, Validation Accuracy: 79.10%\n",
      "Epoch 68: Training Loss: 1.811, Training Accuracy: 56.69%, Validation Loss: 0.881, Validation Accuracy: 78.83%\n",
      "Epoch 69: Training Loss: 1.720, Training Accuracy: 59.15%, Validation Loss: 0.840, Validation Accuracy: 79.13%\n",
      "Epoch 70: Training Loss: 1.791, Training Accuracy: 57.31%, Validation Loss: 0.827, Validation Accuracy: 79.05%\n",
      "Epoch 71: Training Loss: 1.806, Training Accuracy: 56.22%, Validation Loss: 0.870, Validation Accuracy: 78.96%\n",
      "Epoch 72: Training Loss: 1.787, Training Accuracy: 57.44%, Validation Loss: 0.852, Validation Accuracy: 79.10%\n",
      "Epoch 73: Training Loss: 1.757, Training Accuracy: 57.82%, Validation Loss: 0.831, Validation Accuracy: 79.10%\n",
      "Epoch 74: Training Loss: 1.785, Training Accuracy: 56.12%, Validation Loss: 0.836, Validation Accuracy: 79.23%\n",
      "Epoch 75: Training Loss: 1.693, Training Accuracy: 59.13%, Validation Loss: 0.819, Validation Accuracy: 79.27%\n",
      "Epoch 76: Training Loss: 1.821, Training Accuracy: 55.65%, Validation Loss: 0.864, Validation Accuracy: 79.07%\n",
      "Epoch 77: Training Loss: 1.690, Training Accuracy: 58.91%, Validation Loss: 0.840, Validation Accuracy: 79.12%\n",
      "Epoch 78: Training Loss: 1.735, Training Accuracy: 59.52%, Validation Loss: 0.887, Validation Accuracy: 78.97%\n",
      "Epoch 79: Training Loss: 1.780, Training Accuracy: 57.03%, Validation Loss: 0.834, Validation Accuracy: 79.19%\n",
      "Epoch 80: Training Loss: 1.801, Training Accuracy: 56.43%, Validation Loss: 0.833, Validation Accuracy: 79.14%\n",
      "Epoch 81: Training Loss: 1.781, Training Accuracy: 56.93%, Validation Loss: 0.830, Validation Accuracy: 78.99%\n",
      "Epoch 82: Training Loss: 1.727, Training Accuracy: 58.71%, Validation Loss: 0.848, Validation Accuracy: 79.04%\n",
      "Epoch 83: Training Loss: 1.747, Training Accuracy: 57.58%, Validation Loss: 0.820, Validation Accuracy: 79.09%\n",
      "Epoch 84: Training Loss: 1.794, Training Accuracy: 56.98%, Validation Loss: 0.827, Validation Accuracy: 78.94%\n",
      "Epoch 85: Training Loss: 1.741, Training Accuracy: 58.19%, Validation Loss: 0.823, Validation Accuracy: 79.13%\n",
      "Epoch 86: Training Loss: 1.806, Training Accuracy: 56.82%, Validation Loss: 0.844, Validation Accuracy: 79.19%\n",
      "Epoch 87: Training Loss: 1.764, Training Accuracy: 57.17%, Validation Loss: 0.822, Validation Accuracy: 79.13%\n",
      "Epoch 88: Training Loss: 1.770, Training Accuracy: 56.25%, Validation Loss: 0.821, Validation Accuracy: 79.23%\n",
      "Epoch 89: Training Loss: 1.735, Training Accuracy: 58.09%, Validation Loss: 0.848, Validation Accuracy: 79.15%\n",
      "Epoch 90: Training Loss: 1.755, Training Accuracy: 57.69%, Validation Loss: 0.841, Validation Accuracy: 79.01%\n",
      "Epoch 91: Training Loss: 1.715, Training Accuracy: 58.42%, Validation Loss: 0.815, Validation Accuracy: 79.04%\n",
      "Epoch 92: Training Loss: 1.714, Training Accuracy: 57.79%, Validation Loss: 0.845, Validation Accuracy: 78.98%\n",
      "Epoch 93: Training Loss: 1.739, Training Accuracy: 57.05%, Validation Loss: 0.842, Validation Accuracy: 79.10%\n",
      "Epoch 94: Training Loss: 1.747, Training Accuracy: 57.66%, Validation Loss: 0.829, Validation Accuracy: 78.89%\n",
      "Epoch 95: Training Loss: 1.741, Training Accuracy: 57.92%, Validation Loss: 0.844, Validation Accuracy: 79.08%\n",
      "Epoch 96: Training Loss: 1.702, Training Accuracy: 59.29%, Validation Loss: 0.850, Validation Accuracy: 79.18%\n",
      "Epoch 97: Training Loss: 1.770, Training Accuracy: 57.36%, Validation Loss: 0.837, Validation Accuracy: 79.16%\n",
      "Epoch 98: Training Loss: 1.757, Training Accuracy: 57.89%, Validation Loss: 0.854, Validation Accuracy: 78.97%\n",
      "Epoch 99: Training Loss: 1.755, Training Accuracy: 57.42%, Validation Loss: 0.864, Validation Accuracy: 78.95%\n",
      "Epoch 100: Training Loss: 1.801, Training Accuracy: 56.57%, Validation Loss: 0.855, Validation Accuracy: 78.84%\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "for epoch in range(100):  # 共训练100个epoch\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # 应用CutMix\n",
    "        inputs, targets_a, targets_b, lam = cutmix_data(inputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (lam * (predicted == targets_a).sum().item() + (1 - lam) * (predicted == targets_b).sum().item())\n",
    "\n",
    "    train_loss = running_loss / len(trainloader)\n",
    "    train_accuracy = 100 * correct / total\n",
    "\n",
    "    writer.add_scalar('training loss', train_loss, epoch)\n",
    "    writer.add_scalar('training accuracy', train_accuracy, epoch)\n",
    "\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # 验证模型\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(testloader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "\n",
    "    writer.add_scalar('validation loss', val_loss, epoch)\n",
    "    writer.add_scalar('validation accuracy', val_accuracy, epoch)\n",
    "\n",
    "    print(f'Epoch {epoch + 1}: Training Loss: {train_loss:.3f}, Training Accuracy: {train_accuracy:.2f}%, Validation Loss: {val_loss:.3f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "    # 保存验证集上最高准确率的模型\n",
    "    if val_accuracy > best_acc:\n",
    "        best_acc = val_accuracy\n",
    "        torch.save(net.state_dict(), 'resnet34_pretrained.pth')\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefa1596-fc5a-49f2-b1d8-ddf041e8d107",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
